from langchain_ollama import OllamaEmbeddings, ChatOllama
from modules.hyde_rag import contextual_retrieval  # Import contextual_retrieval from the hyde_rag module
from modules.web_search import tavily_search  # Import tavily_search from the web_search module
from langchain.schema import Document

def final_fact_check(question, answer, retriever, debug=False):
    """
    Perform a final fact-check of the answer based on a combined context from retrieved documents and web search results.

    Parameters:
    question (str): The question asked by the user.
    answer (str): The initial answer generated by the RAG or web search.
    retriever: The retriever object created from the vector store.
    debug (bool): If True, print debug information.

    Returns:
    str: The fact-checked and potentially corrected answer.
    """
    # Initialize the LLM for fact-checking
    llm = ChatOllama(model="llama3.2", temperature=0)

    # Retrieve documents using HyDE
    retrieved_docs = contextual_retrieval(question, retriever, debug=debug)
    context = "\n\n".join(doc.page_content for doc in retrieved_docs) if retrieved_docs else ""

    # Retrieve web context using Tavily search
    tavily_context = tavily_search(question, debug=debug)

    # Combine both contexts
    combined_context = context + "\n\n" + tavily_context

    # Debug output for context combination
    if debug:
        print(f"Combined context for fact-checking:\n{combined_context}")

    # Create the fact-checking prompt
    fact_check_prompt = (
        f"Context: {combined_context}\n\nAnswer: {answer}\n\n"
        f"Verify the accuracy of the answer based on the context. Provide a corrected answer if necessary."
    )

    # Generate the fact-checked answer using the LLM
    final_answer = llm.invoke([{"role": "user", "content": fact_check_prompt}]).content

    # Debug output for final answer
    if debug:
        print(f"Fact-checked answer: {final_answer}")

    return final_answer

def main(debug=False):
    """
    Test the final_fact_check function with sample input.
    """
    # Sample question and answer for testing
    question = "What pick of the Draft was Bronny James Jr?"
    initial_answer = "Bronny James Jr. was selected by the Golden State Warriors with the 55th pick."  # Sample incorrect answer

    # Use pre-loaded documents with Bronny James information
    sample_docs = [Document(page_content="Bronny James was selected as the 55th pick in the 2024 NBA Draft.")]
    vectorstore = create_vectorstore(sample_docs, debug=debug)
    retriever = vectorstore.as_retriever()

    # Run the final_fact_check function
    corrected_answer = final_fact_check(question, initial_answer, retriever, debug=debug)
    if debug:
        print(f"Corrected answer after final fact-check: {corrected_answer}")

if __name__ == "__main__":
    main(debug=True)
