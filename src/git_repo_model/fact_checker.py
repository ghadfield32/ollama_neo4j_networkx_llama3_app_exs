from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain.schema import Document

from modules.hyde_rag import contextual_retrieval
from modules.web_search import tavily_search  
from modules.vector_store import create_vectorstore

def final_fact_check(question, answer, retriever, debug=False):
    """
    Perform a final fact-check of the answer based on a combined context from retrieved documents and web search results.

    Parameters:
    question (str): The question asked by the user.
    answer (str): The initial answer generated by the RAG or web search.
    retriever: The retriever object created from the vector store.
    debug (bool): If True, print debug information.

    Returns:
    str: The fact-checked and potentially corrected answer.
    """
    # Initialize the LLM for fact-checking
    llm = ChatOllama(model="llama3.2", temperature=0)

    # Retrieve documents using HyDE
    retrieved_docs = contextual_retrieval(question, retriever, debug=debug)
    context = "\n\n".join(doc.page_content for doc in retrieved_docs) if retrieved_docs else ""

    # Retrieve web context using Tavily search
    tavily_context = tavily_search(question, debug=debug)

    # Combine both contexts
    combined_context = context + "\n\n" + tavily_context

    # Debug output for context combination
    if debug:
        print(f"Combined context for fact-checking:\n{combined_context}")

    # Create the fact-checking prompt
    fact_check_prompt = (
        f"Context: {combined_context}\n\nAnswer: {answer}\n\n"
        f"Verify the accuracy of the answer based on the context. Provide a corrected answer if necessary."
    )

    # Generate the fact-checked answer using the LLM
    final_answer = llm.invoke([{"role": "user", "content": fact_check_prompt}]).content

    # Debug output for final answer
    if debug:
        print(f"Fact-checked answer: {final_answer}")

    return final_answer

def main(debug=False):
    """
    Test the final_fact_check function with sample input.
    """
    # Sample question and answer for a repository-focused example
    question = "What are the best practices for organizing a local code repository?"
    initial_answer = "Organize files by language, with folders for Python, JavaScript, and SQL scripts."

    # Create a sample retriever for repository organization context
    sample_docs = [
        Document(page_content="Best practices for organizing a code repository include structuring folders by project modules, using clear naming conventions, and maintaining a README for documentation.", metadata={"file_name": "repo_organization_guide.md"}),
        Document(page_content="Consider creating separate folders for data, scripts, and tests. A well-documented repository is easier for collaboration and maintenance.", metadata={"file_name": "repo_best_practices.md"})
    ]
    vectorstore = create_vectorstore(sample_docs, debug=debug)
    retriever = vectorstore.as_retriever()

    # Run the final_fact_check function
    corrected_answer = final_fact_check(question, initial_answer, retriever, debug=debug)
    if debug:
        print(f"Corrected answer after final fact-check: {corrected_answer}")

if __name__ == "__main__":
    main(debug=True)
