{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repository Structure\n",
    "\n",
    "Create the following Python modules:\n",
    "\n",
    "    data_preprocessing.py: Handles data loading and preprocessing.\n",
    "    neo4j_data_preprocess_ingest.py: Manages Neo4j database connections, schema setup, and data ingestion.\n",
    "    neo4j_test_functions.py: Contains functions to test and query data from Neo4j.\n",
    "    model_loading.py: Responsible for loading and testing the LLM model.\n",
    "    graphqa_functions.py: Sets Neo4j permissions and integrates with GraphQA using LangChain.\n",
    "    utility_functions.py: Houses shared utility functions.\n",
    "    main.py: Serves as the entry point to run and test individual modules.\n",
    "\n",
    "Each module will have:\n",
    "\n",
    "    A main() function for individual testing.\n",
    "    A --debug command-line option to enable detailed logging.\n",
    "    Exception handling to trace and identify issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/utility_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/utility_functions.py\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "def load_env_variables():\n",
    "    \"\"\"Loads environment variables from .env file and returns as dictionary.\"\"\"\n",
    "    load_dotenv('../../.env')\n",
    "    return {\n",
    "        'NEO4J_URI': os.getenv(\"NEO4J_URI\"),\n",
    "        'NEO4J_USERNAME': os.getenv(\"NEO4J_USERNAME\"),\n",
    "        'NEO4J_PASSWORD': os.getenv(\"NEO4J_PASSWORD\")\n",
    "    }\n",
    "\n",
    "def connect_to_neo4j():\n",
    "    \"\"\"Connects to the Neo4j database using credentials from environment variables.\"\"\"\n",
    "    env_vars = load_env_variables()\n",
    "    uri = env_vars['NEO4J_URI']\n",
    "    username = env_vars['NEO4J_USERNAME']\n",
    "    password = env_vars['NEO4J_PASSWORD']\n",
    "    \n",
    "    try:\n",
    "        driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "        driver.verify_connectivity()\n",
    "        print(\"Connected to Neo4j successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to Neo4j: {e}\")\n",
    "        raise\n",
    "    return driver\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to test Neo4j connection.\"\"\"\n",
    "    print(\"Testing Neo4j connection...\")\n",
    "    try:\n",
    "        driver = connect_to_neo4j()\n",
    "        driver.close()  # Close the connection after testing\n",
    "        print(\"Neo4j connection test completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Neo4j connection test failed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/data_cleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/data_cleaning.py\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Loads data from the specified CSV file path.\"\"\"\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    return dataframe\n",
    "\n",
    "def initial_data_check(dataframe, debug=False):\n",
    "    \"\"\"Performs initial data checks, including missing values, data types, and unique counts.\"\"\"\n",
    "    if debug:\n",
    "        print(\"Initial data shape:\", dataframe.shape)\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_values_summary = dataframe.isnull().sum()\n",
    "        print(\"Missing Values Summary:\\n\", missing_values_summary[missing_values_summary > 0])\n",
    "        \n",
    "        # Data types of each column\n",
    "        print(\"Data Types:\\n\", dataframe.dtypes)\n",
    "        \n",
    "        # Count unique values in key columns\n",
    "        unique_counts = dataframe.nunique()\n",
    "        print(\"Unique Values in Key Columns:\\n\", unique_counts[['Player', 'Season', 'Team', 'Salary']])\n",
    "        \n",
    "        # Check if key columns have unexpected unique values\n",
    "        print(f\"Unique Players: {dataframe['Player'].nunique()}\")\n",
    "        print(f\"Unique Seasons: {dataframe['Season'].nunique()}\")\n",
    "        print(f\"Unique Teams: {dataframe['Team'].nunique()}\")\n",
    "        print(f\"Unique Salary values: {dataframe['Salary'].nunique()}\")\n",
    "        \n",
    "def clean_data(dataframe, debug=False):\n",
    "    \"\"\"Cleans and prepares data for Neo4j ingestion, displaying nulls before and after cleaning.\"\"\"\n",
    "    if debug:\n",
    "        print(\"Cleaning data...\")\n",
    "    \n",
    "    # Step 1: Display total nulls before any cleaning\n",
    "    total_nulls_before = dataframe.isnull().sum().sum()\n",
    "    if debug:\n",
    "        print(\"Total null values before cleaning:\", total_nulls_before)\n",
    "        print(\"Null values by column before cleaning:\\n\", dataframe.isnull().sum())\n",
    "\n",
    "    # Remove '2nd Apron' column if it exists\n",
    "    if '2nd Apron' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['2nd Apron'])\n",
    "        if debug:\n",
    "            print(\"Dropped '2nd Apron' column.\")\n",
    "\n",
    "    # Fill missing values in 'Injury_Periods' with 'Not_injured'\n",
    "    dataframe['Injury_Periods'] = dataframe['Injury_Periods'].fillna(\"Not_injured\")\n",
    "    if debug:\n",
    "        print(\"Filled missing 'Injury_Periods' with 'Not_injured'.\")\n",
    "\n",
    "    # Step 2: Drop rows with any remaining missing values\n",
    "    dataframe_cleaned = dataframe.dropna()\n",
    "    \n",
    "    # Step 3: Display total nulls after cleaning\n",
    "    total_nulls_after = dataframe_cleaned.isnull().sum().sum()\n",
    "    if debug:\n",
    "        print(\"Total null values after cleaning:\", total_nulls_after)\n",
    "        print(\"Null values by column after cleaning:\\n\", dataframe_cleaned.isnull().sum())\n",
    "        print(\"Data shape after dropping remaining NaNs:\", dataframe_cleaned.shape)\n",
    "    \n",
    "    return dataframe_cleaned\n",
    "\n",
    "\n",
    "def check_for_duplicates(dataframe, debug=False):\n",
    "    \"\"\"Checks and logs duplicate entries in the dataframe.\"\"\"\n",
    "    duplicates = dataframe.duplicated(subset=[\"Player\", \"Season\", \"Salary\"])\n",
    "    num_duplicates = duplicates.sum()\n",
    "    if debug:\n",
    "        print(\"Number of duplicate rows:\", num_duplicates)\n",
    "    if num_duplicates > 0:\n",
    "        print(\"Duplicate rows based on [Player, Season, Salary]:\\n\", dataframe[duplicates])\n",
    "\n",
    "def map_team_ids(dataframe, debug=False):\n",
    "    \"\"\"Maps team abbreviations to TeamID.\"\"\"\n",
    "    team_id_mapping = {\n",
    "        \"ATL\": 1610612737, \"BOS\": 1610612738, \"BKN\": 1610612751, \"CHA\": 1610612766,\n",
    "        \"CHI\": 1610612741, \"CLE\": 1610612739, \"DAL\": 1610612742, \"DEN\": 1610612743,\n",
    "        \"DET\": 1610612765, \"GSW\": 1610612744, \"HOU\": 1610612745, \"IND\": 1610612754,\n",
    "        \"LAC\": 1610612746, \"LAL\": 1610612747, \"MEM\": 1610612763, \"MIA\": 1610612748,\n",
    "        \"MIL\": 1610612749, \"MIN\": 1610612750, \"NOP\": 1610612740, \"NYK\": 1610612752,\n",
    "        \"OKC\": 1610612760, \"ORL\": 1610612753, \"PHI\": 1610612755, \"PHX\": 1610612756,\n",
    "        \"POR\": 1610612757, \"SAC\": 1610612758, \"SAS\": 1610612759, \"TOR\": 1610612761,\n",
    "        \"UTA\": 1610612762, \"WAS\": 1610612764\n",
    "    }\n",
    "    dataframe['TeamID'] = dataframe['Team'].map(team_id_mapping)\n",
    "    if debug:\n",
    "        unmapped_teams = dataframe['TeamID'].isnull().sum()\n",
    "        if unmapped_teams > 0:\n",
    "            print(f\"{unmapped_teams} teams were not mapped to TeamIDs. Check team abbreviations.\")\n",
    "    return dataframe\n",
    "\n",
    "def add_suffixes_to_columns(dataframe, debug=False):\n",
    "    \"\"\"Renames statistical columns to include '_total' suffix where needed.\"\"\"\n",
    "    suffix_mapping = {\n",
    "        'PTS': 'PTS_total', 'AST': 'AST_total', 'TRB': 'TRB_total', 'STL': 'STL_total',\n",
    "        'BLK': 'BLK_total', 'TOV': 'TOV_total', 'PF': 'PF_total', 'WS': 'WS_total',\n",
    "        'OWS': 'OWS_total', 'DWS': 'DWS_total', 'VORP': 'VORP_total'\n",
    "    }\n",
    "    dataframe = dataframe.rename(columns=suffix_mapping)\n",
    "    if debug:\n",
    "        print(\"Applied suffixes to cumulative columns.\")\n",
    "    return dataframe\n",
    "\n",
    "def final_data_check(dataframe, debug=False):\n",
    "    \"\"\"Final data checks before saving for Neo4j ingestion.\"\"\"\n",
    "    if debug:\n",
    "        # Verify all necessary columns exist\n",
    "        required_columns = ['Player', 'Season', 'TeamID', 'Salary'] + list(dataframe.filter(regex='_total').columns)\n",
    "        missing_columns = [col for col in required_columns if col not in dataframe.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"Missing expected columns: {missing_columns}\")\n",
    "        \n",
    "        # Re-check for missing values\n",
    "        null_summary = dataframe.isnull().sum()\n",
    "        if null_summary.any():\n",
    "            print(\"Columns with remaining null values:\\n\", null_summary[null_summary > 0])\n",
    "        \n",
    "        # Check if data types are compatible for Neo4j\n",
    "        print(\"Final Data Types:\\n\", dataframe.dtypes)\n",
    "\n",
    "        # Preview the first few rows of the final dataframe\n",
    "        print(\"Preview of cleaned data:\\n\", dataframe.head())\n",
    "\n",
    "def check_data_statistics(dataframe, debug=False):\n",
    "    \"\"\"Generates descriptive statistics and checks for unique counts to spot anomalies.\"\"\"\n",
    "    if debug:\n",
    "        print(\"Descriptive Statistics of the Dataset:\\n\", dataframe.describe(include='all'))\n",
    "        print(\"\\nUnique Value Counts for Key Columns:\")\n",
    "        unique_counts = dataframe.nunique()\n",
    "        print(unique_counts[['Player', 'Season', 'Team', 'Salary']])\n",
    "        print(f\"\\nUnique Players: {dataframe['Player'].nunique()}\")\n",
    "        print(f\"Unique Seasons: {dataframe['Season'].nunique()}\")\n",
    "        print(f\"Unique Teams: {dataframe['Team'].nunique()}\")\n",
    "        print(f\"Unique Contracts (based on Salary): {dataframe['Salary'].nunique()}\")\n",
    "\n",
    "def identify_conflicting_contracts(dataframe, debug=False):\n",
    "    \"\"\"Identifies conflicting contracts and displays detailed entries for conflicts.\"\"\"\n",
    "    conflicting_contracts = dataframe.groupby(['Player', 'Season', 'Salary']).size().reset_index(name='count')\n",
    "    conflicting_contracts = conflicting_contracts[conflicting_contracts['count'] > 1]\n",
    "    \n",
    "    if not conflicting_contracts.empty:\n",
    "        print(\"Potential Conflicting Contracts Found:\")\n",
    "        print(conflicting_contracts)\n",
    "        for _, row in conflicting_contracts.iterrows():\n",
    "            player, season, salary = row['Player'], row['Season'], row['Salary']\n",
    "            print(f\"\\nDetails of Conflicting Contracts for Player: {player}, Season: {season}, Salary: {salary}\")\n",
    "            print(dataframe[(dataframe['Player'] == player) & \n",
    "                            (dataframe['Season'] == season) & \n",
    "                            (dataframe['Salary'] == salary)])\n",
    "\n",
    "def data_initial_summary(dataframe, debug=False):\n",
    "    \"\"\"Performs initial checks and calls the detailed statistics and conflict identification functions.\"\"\"\n",
    "    initial_data_check(dataframe, debug)\n",
    "    check_data_statistics(dataframe, debug)\n",
    "    identify_conflicting_contracts(dataframe, debug)\n",
    "\n",
    "\n",
    "def main(debug=True):\n",
    "    load_dotenv('/workspaces/custom_ollama_docker/.env')\n",
    "    data_file = os.getenv('DATA_FILE', '/workspaces/custom_ollama_docker/data/neo4j/raw/nba_player_data_final_inflated.csv')\n",
    "    output_file = os.getenv('CLEANED_DATA_FILE', '/workspaces/custom_ollama_docker/data/neo4j/processed/nba_player_data_cleaned.csv')\n",
    "    \n",
    "    try:\n",
    "        dataframe = load_data(data_file)\n",
    "        print(f\"Loaded data with shape: {dataframe.shape}\")\n",
    "        \n",
    "        # Step 2: Initial checks, data statistics, and conflict identification\n",
    "        data_initial_summary(dataframe, debug)\n",
    "        \n",
    "        # Clean data, check duplicates, map IDs, add suffixes, and run final checks\n",
    "        dataframe_cleaned = clean_data(dataframe, debug)\n",
    "        check_for_duplicates(dataframe_cleaned, debug)\n",
    "        dataframe_mapped = map_team_ids(dataframe_cleaned, debug)\n",
    "        dataframe_final = add_suffixes_to_columns(dataframe_mapped, debug)\n",
    "        final_data_check(dataframe_final, debug)\n",
    "        \n",
    "        dataframe_final.to_csv(output_file, index=False)\n",
    "        print(f\"Preprocessed data saved to {output_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during data preprocessing:\", e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/neo4j_data_preprocess_ingest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/neo4j_data_preprocess_ingest.py\n",
    "from utility_functions import load_env_variables, connect_to_neo4j\n",
    "\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "# Function to create constraints only if they don't already exist\n",
    "def create_constraint_if_not_exists(session, constraint_query, constraint_name):\n",
    "    check_query = f\"SHOW CONSTRAINTS WHERE name = '{constraint_name}'\"\n",
    "    result = session.run(check_query)\n",
    "    if result.single():\n",
    "        print(f\"Constraint '{constraint_name}' already exists.\")\n",
    "    else:\n",
    "        session.run(constraint_query)\n",
    "        print(f\"Successfully created constraint: {constraint_name}\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to delete duplicate nodes before creating uniqueness constraints\n",
    "def delete_duplicate_nodes(session, label, property_name):\n",
    "    print(f\"Deleting duplicate nodes for {label} based on {property_name}...\")\n",
    "    delete_query = f\"\"\"\n",
    "    MATCH (n:{label})\n",
    "    WITH n.{property_name} AS prop, COLLECT(n) AS nodes\n",
    "    WHERE SIZE(nodes) > 1\n",
    "    UNWIND TAIL(nodes) AS duplicateNode\n",
    "    DETACH DELETE duplicateNode\n",
    "    \"\"\"\n",
    "    session.run(delete_query)\n",
    "    print(f\"Duplicate nodes deleted for {label} based on {property_name}.\")\n",
    "\n",
    "# Setup schema with constraints and cleanup\n",
    "def setup_schema_with_cleanup(session):\n",
    "    constraints = [\n",
    "        {\"query\": \"CREATE CONSTRAINT player_name_unique FOR (p:Player) REQUIRE p.name IS UNIQUE\", \"name\": \"player_name_unique\"},\n",
    "        {\"query\": \"CREATE CONSTRAINT team_name_unique FOR (t:Team) REQUIRE t.name IS UNIQUE\", \"name\": \"team_name_unique\"},\n",
    "        {\"query\": \"CREATE CONSTRAINT season_name_unique FOR (s:Season) REQUIRE s.name IS UNIQUE\", \"name\": \"season_name_unique\"},\n",
    "        {\"query\": \"CREATE CONSTRAINT position_name_unique FOR (pos:Position) REQUIRE pos.name IS UNIQUE\", \"name\": \"position_name_unique\"},\n",
    "        {\"query\": \"CREATE CONSTRAINT contract_unique FOR (c:Contract) REQUIRE (c.salary, c.player_name, c.season) IS UNIQUE\", \"name\": \"contract_unique\"},\n",
    "    ]\n",
    "\n",
    "    cleanup_mappings = [\n",
    "        {\"label\": \"Player\", \"property\": \"name\"},\n",
    "        {\"label\": \"Team\", \"property\": \"name\"},\n",
    "        {\"label\": \"Season\", \"property\": \"name\"},\n",
    "        {\"label\": \"Position\", \"property\": \"name\"},\n",
    "        {\"label\": \"Contract\", \"property\": \"salary\"}\n",
    "    ]\n",
    "\n",
    "    for mapping in cleanup_mappings:\n",
    "        delete_duplicate_nodes(session, mapping[\"label\"], mapping[\"property\"])\n",
    "\n",
    "    for constraint in constraints:\n",
    "        create_constraint_if_not_exists(session, constraint[\"query\"], constraint[\"name\"])\n",
    "\n",
    "\n",
    "\n",
    "def create_player_node(tx, player_data):\n",
    "    query = \"\"\"\n",
    "    MERGE (p:Player {name: $name})\n",
    "    ON CREATE SET p.age = $age,\n",
    "                  p.position = $position,\n",
    "                  p.years_of_service = $years_of_service,\n",
    "                  p.injury_risk = $injury_risk,\n",
    "                  p.season_salary = $salary,\n",
    "                  p.season = $season,\n",
    "                  p.per = $per,\n",
    "                  p.ws = $ws,\n",
    "                  p.bpm = $bpm,\n",
    "                  p.vorp = $vorp\n",
    "    \"\"\"\n",
    "    tx.run(query,\n",
    "           name=player_data[\"Player\"],\n",
    "           age=player_data[\"Age\"],\n",
    "           position=player_data[\"Position\"],\n",
    "           years_of_service=player_data[\"Years of Service\"],\n",
    "           injury_risk=player_data[\"Injury_Risk\"],\n",
    "           salary=player_data[\"Salary\"],\n",
    "           season=player_data[\"Season\"],\n",
    "           per=player_data.get(\"PER\"),\n",
    "           ws=player_data.get(\"WS\"),\n",
    "           bpm=player_data.get(\"BPM\"),\n",
    "           vorp=player_data.get(\"VORP\"))\n",
    "\n",
    "\n",
    "def create_team_node(tx, team_name, team_id, team_data):\n",
    "    query = \"\"\"\n",
    "    MERGE (t:Team {name: $name})\n",
    "    ON CREATE SET t.team_id = $team_id,\n",
    "                  t.needs = $needs,\n",
    "                  t.strategy = $strategy,\n",
    "                  t.cap_space = $cap_space\n",
    "    \"\"\"\n",
    "    tx.run(query,\n",
    "           name=team_name,\n",
    "           team_id=team_id,\n",
    "           needs=team_data.get(\"Needs\"),\n",
    "           strategy=team_data.get(\"Strategy\"),\n",
    "           cap_space=team_data.get(\"Cap Space\"))\n",
    "\n",
    "\n",
    "def create_season_node(tx, season):\n",
    "    query = \"\"\"\n",
    "    MERGE (s:Season {name: $season})\n",
    "    \"\"\"\n",
    "    tx.run(query, season=season)\n",
    "\n",
    "\n",
    "def create_position_node(tx, position):\n",
    "    query = \"\"\"\n",
    "    MERGE (pos:Position {name: $position})\n",
    "    \"\"\"\n",
    "    tx.run(query, position=position)\n",
    "\n",
    "\n",
    "def create_contract_node(tx, contract_data):\n",
    "    query = \"\"\"\n",
    "    MERGE (c:Contract {player_name: $player_name, season: $season})\n",
    "    ON CREATE SET c.salary = $salary,\n",
    "                  c.cap = $cap,\n",
    "                  c.luxury_tax = $luxury_tax,\n",
    "                  c.duration = $duration,\n",
    "                  c.player_option = $player_option,\n",
    "                  c.team_option = $team_option,\n",
    "                  c.no_trade_clause = $no_trade_clause\n",
    "    \"\"\"\n",
    "    tx.run(query,\n",
    "           player_name=contract_data[\"Player\"],\n",
    "           season=contract_data[\"Season\"],\n",
    "           salary=contract_data[\"Salary\"],\n",
    "           cap=contract_data[\"Salary Cap\"],\n",
    "           luxury_tax=contract_data[\"Luxury Tax\"],\n",
    "           duration=contract_data.get(\"Contract Duration\"),\n",
    "           player_option=contract_data.get(\"Player Option\"),\n",
    "           team_option=contract_data.get(\"Team Option\"),\n",
    "           no_trade_clause=contract_data.get(\"No Trade Clause\"))\n",
    "\n",
    "\n",
    "def delete_duplicate_contract_nodes(session):\n",
    "    delete_query = \"\"\"\n",
    "    MATCH (c:Contract)\n",
    "    WITH c.salary AS salary, c.player_name AS player_name, c.season AS season, COLLECT(c) AS contracts\n",
    "    WHERE SIZE(contracts) > 1\n",
    "    UNWIND TAIL(contracts) AS duplicateContract\n",
    "    DETACH DELETE duplicateContract\n",
    "    \"\"\"\n",
    "    session.run(delete_query)\n",
    "    print(\"Duplicate Contract nodes deleted based on salary, player_name, and season.\")\n",
    "\n",
    "\n",
    "def create_statistics_node(tx, player_name, stats_data):\n",
    "    query = \"\"\"\n",
    "    MERGE (stat:Statistics {player: $player, season: $season})\n",
    "    ON CREATE SET \n",
    "        stat.ppg = $pts_total,               // Use total fields\n",
    "        stat.assists_total = $ast_total,\n",
    "        stat.rebounds_total = $trb_total,\n",
    "        stat.steals_total = $stl_total,\n",
    "        stat.blocks_total = $blk_total,\n",
    "        stat.turnovers_total = $tov_total,\n",
    "        stat.personal_fouls_total = $pf_total,\n",
    "        stat.win_shares_total = $ws_total,\n",
    "        stat.offensive_win_shares_total = $ows_total,\n",
    "        stat.defensive_win_shares_total = $dws_total,\n",
    "        stat.vorp_total = $vorp_total,\n",
    "        stat.games_played = $games_played  // Retain games played without \"total\" as it isn't cumulative\n",
    "    \"\"\"\n",
    "    tx.run(query, \n",
    "           player=player_name, \n",
    "           season=stats_data[\"Season\"], \n",
    "           pts_total=stats_data[\"PTS_total\"], \n",
    "           ast_total=stats_data[\"AST_total\"], \n",
    "           trb_total=stats_data[\"TRB_total\"], \n",
    "           stl_total=stats_data[\"STL_total\"],\n",
    "           blk_total=stats_data[\"BLK_total\"],\n",
    "           tov_total=stats_data[\"TOV_total\"],\n",
    "           pf_total=stats_data[\"PF_total\"],\n",
    "           ws_total=stats_data[\"WS_total\"],\n",
    "           ows_total=stats_data[\"OWS_total\"],\n",
    "           dws_total=stats_data[\"DWS_total\"],\n",
    "           vorp_total=stats_data[\"VORP_total\"],\n",
    "           games_played=stats_data[\"GP\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_injury_node(tx, player_name, injury_data):\n",
    "    if pd.isna(injury_data[\"Total_Days_Injured\"]) or pd.isna(injury_data[\"Injury_Periods\"]) or pd.isna(injury_data[\"Injury_Risk\"]):\n",
    "        return\n",
    "    query = \"\"\"\n",
    "    MERGE (i:Injury {player: $player})\n",
    "    ON CREATE SET i.total_days = $total_days,\n",
    "                  i.injury_periods = $injury_periods,\n",
    "                  i.risk = $risk,\n",
    "                  i.injury_history = $injury_history\n",
    "    \"\"\"\n",
    "    tx.run(query,\n",
    "           player=player_name,\n",
    "           total_days=injury_data[\"Total_Days_Injured\"],\n",
    "           injury_periods=injury_data[\"Injury_Periods\"],\n",
    "           risk=injury_data[\"Injury_Risk\"],\n",
    "           injury_history=injury_data.get(\"Injury_History\"))\n",
    "\n",
    "\n",
    "def create_relationships(tx, player_data):\n",
    "    \"\"\"Create relationships between Player, Team, Season, Contract, and other nodes in the database.\"\"\"\n",
    "    relationships = [\n",
    "        {\n",
    "            \"query\": \"\"\"\n",
    "                MATCH (p:Player {name: $player}), (t:Team {name: $team}), (s:Season {name: $season})\n",
    "                MERGE (p)-[:HAS_PLAYED_FOR {season: $season}]->(t)\n",
    "                MERGE (p)-[:PARTICIPATED_IN]->(s)\n",
    "            \"\"\",\n",
    "            \"params\": {\"player\": player_data[\"Player\"], \"team\": player_data[\"Team\"], \"season\": player_data[\"Season\"]}\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"\"\"\n",
    "                MATCH (p:Player {name: $player}), (c:Contract {salary: $salary, season: $season})\n",
    "                MERGE (p)-[:HAS_CONTRACT {season: $season}]->(c)\n",
    "            \"\"\",\n",
    "            \"params\": {\"player\": player_data[\"Player\"], \"salary\": player_data[\"Salary\"], \"season\": player_data[\"Season\"]}\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"\"\"\n",
    "                MATCH (p:Player {name: $player}), (stat:Statistics {player: $player, season: $season})\n",
    "                MERGE (p)-[:POSSESSES {season: $season}]->(stat)\n",
    "            \"\"\",\n",
    "            \"params\": {\"player\": player_data[\"Player\"], \"season\": player_data[\"Season\"]}\n",
    "        },\n",
    "        # Additional relationships for injury and current team\n",
    "    ]\n",
    "    for rel in relationships:\n",
    "        tx.run(rel[\"query\"], **rel[\"params\"])\n",
    "    print(f\"Relationships created for Player: {player_data['Player']} for season: {player_data['Season']}.\")\n",
    "\n",
    "\n",
    "def calculate_and_set_trade_value(tx, player_name):\n",
    "    # Placeholder for actual calculation logic\n",
    "    trade_value = 0  # Replace with real calculation if needed\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Player {name: $player})\n",
    "    SET p.trade_value = $trade_value\n",
    "    \"\"\"\n",
    "    tx.run(query, player=player_name, trade_value=trade_value)\n",
    "\n",
    "\n",
    "# Example query to check indexes\n",
    "def check_indexes(session):\n",
    "    result = session.run(\"CALL db.indexes\")\n",
    "    for record in result:\n",
    "        print(record)\n",
    "\n",
    "\n",
    "def clear_database(session):\n",
    "    delete_query = \"MATCH (n) DETACH DELETE n\"\n",
    "    session.run(delete_query)\n",
    "    print(\"All nodes and relationships deleted from the database.\")\n",
    "\n",
    "\n",
    "# Function to clear all constraints and indexes\n",
    "def clear_constraints_and_indexes(session):\n",
    "    # Delete all constraints\n",
    "    print(\"Clearing all constraints...\")\n",
    "    constraints_result = session.run(\"SHOW CONSTRAINTS\")\n",
    "    for record in constraints_result:\n",
    "        constraint_name = record['name']\n",
    "        session.run(f\"DROP CONSTRAINT {constraint_name}\")\n",
    "        print(f\"Constraint '{constraint_name}' has been deleted.\")\n",
    "    \n",
    "    # Delete all indexes\n",
    "    print(\"Clearing all indexes...\")\n",
    "    indexes_result = session.run(\"SHOW INDEXES\")\n",
    "    for record in indexes_result:\n",
    "        index_name = record['name']\n",
    "        session.run(f\"DROP INDEX {index_name}\")\n",
    "        print(f\"Index '{index_name}' has been deleted.\")\n",
    "\n",
    "\n",
    "# Function to create indexes if they don't already exist\n",
    "def create_index_if_not_exists(session, index_query, index_name):\n",
    "    try:\n",
    "        check_query = f\"SHOW INDEXES WHERE name = '{index_name}'\"\n",
    "        result = session.run(check_query)\n",
    "        if result.single():\n",
    "            print(f\"Index '{index_name}' already exists.\")\n",
    "        else:\n",
    "            session.run(index_query)\n",
    "            print(f\"Successfully created index: {index_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create index: {index_name}. Error: {e}\")\n",
    "\n",
    "\n",
    "# Function to set up indexes\n",
    "def setup_indexes(session):\n",
    "    indexes = [\n",
    "        {\"query\": \"CREATE INDEX player_name_index IF NOT EXISTS FOR (p:Player) ON (p.name)\", \"name\": \"player_name_index\"},\n",
    "        {\"query\": \"CREATE INDEX team_name_index IF NOT EXISTS FOR (t:Team) ON (t.name)\", \"name\": \"team_name_index\"},\n",
    "        {\"query\": \"CREATE INDEX contract_season_index IF NOT EXISTS FOR (c:Contract) ON (c.season)\", \"name\": \"contract_season_index\"}\n",
    "    ]\n",
    "\n",
    "    for index in indexes:\n",
    "        create_index_if_not_exists(session, index[\"query\"], index[\"name\"])\n",
    "\n",
    "\n",
    "# Function to insert data into Neo4j\n",
    "def insert_enhanced_data(tx, player_data):\n",
    "    create_player_node(tx, player_data)\n",
    "    create_team_node(tx, player_data[\"Team\"], player_data[\"TeamID\"], player_data)\n",
    "    create_season_node(tx, player_data[\"Season\"])\n",
    "    create_contract_node(tx, player_data)\n",
    "    create_statistics_node(tx, player_data[\"Player\"], player_data)\n",
    "    create_injury_node(tx, player_data[\"Player\"], player_data)\n",
    "    create_relationships(tx, player_data)\n",
    "\n",
    "\n",
    "# Main function to insert data\n",
    "def main():\n",
    "    load_dotenv('../../.env')\n",
    "    data_file = '../../data/neo4j/processed/nba_player_data_cleaned.csv'\n",
    "\n",
    "    try:\n",
    "        driver = connect_to_neo4j()\n",
    "        dataframe = pd.read_csv(data_file)\n",
    "        data_dicts = dataframe.to_dict(orient='records')\n",
    "        print(f\"Loaded {len(data_dicts)} records from {data_file}.\")\n",
    "\n",
    "        with driver.session() as session:\n",
    "            clear_database(session)\n",
    "            clear_constraints_and_indexes(session)\n",
    "            setup_schema_with_cleanup(session)\n",
    "            setup_indexes(session)\n",
    "            print(\"Database schema and indexes set up successfully.\")\n",
    "\n",
    "            for player_data in data_dicts:\n",
    "                session.execute_write(insert_enhanced_data, player_data)\n",
    "                session.execute_write(calculate_and_set_trade_value, player_data[\"Player\"])\n",
    "\n",
    "            print(\"Data inserted into Neo4j successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during Neo4j data ingestion:\", e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/neo4j_test_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/neo4j_test_functions.py\n",
    "from utility_functions import load_env_variables, connect_to_neo4j\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def query_to_dataframe(driver, query, parameters=None):\n",
    "    \"\"\"Runs a Cypher query and returns a pandas DataFrame.\"\"\"\n",
    "    print(f\"Running query: {query}\")\n",
    "    print(f\"With parameters: {parameters}\")\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, parameters)\n",
    "        columns = result.keys()\n",
    "        data = [record.values() for record in result]\n",
    "        \n",
    "        print(f\"Query returned {len(data)} records.\")\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "def get_player_statistics(driver, season):\n",
    "    \"\"\"Retrieves player statistics for a given season.\"\"\"\n",
    "    print(f\"Fetching player statistics for season: {season}\")\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Player)-[:POSSESSES]->(stat:Statistics {season: $season})\n",
    "    RETURN p.name AS player, stat.ppg AS points_per_game, stat.assists_total AS assists, stat.rebounds_total AS rebounds\n",
    "    ORDER BY stat.ppg DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    parameters = {\"season\": season}\n",
    "    return query_to_dataframe(driver, query, parameters)\n",
    "\n",
    "def get_player_contracts(driver, season):\n",
    "    \"\"\"Retrieves player contracts for a given season.\"\"\"\n",
    "    print(f\"Fetching player contracts for season: {season}\")\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Player)-[:HAS_CONTRACT]->(c:Contract {season: $season})\n",
    "    RETURN p.name AS player, c.salary AS salary, c.duration AS contract_duration\n",
    "    ORDER BY c.salary DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    parameters = {\"season\": season}\n",
    "    return query_to_dataframe(driver, query, parameters)\n",
    "\n",
    "def get_top_teams_by_salary(driver, season):\n",
    "    \"\"\"Retrieves teams ranked by total salary for a given season.\"\"\"\n",
    "    print(f\"Fetching top teams by salary for season: {season}\")\n",
    "    query = \"\"\"\n",
    "    MATCH (t:Team)<-[:HAS_PLAYED_FOR]-(p:Player)-[:HAS_CONTRACT]->(c:Contract {season: $season})\n",
    "    RETURN t.name AS team, SUM(c.salary) AS total_salary\n",
    "    ORDER BY total_salary DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    parameters = {\"season\": season}\n",
    "    return query_to_dataframe(driver, query, parameters)\n",
    "\n",
    "def get_players_with_high_injury_risk(driver):\n",
    "    \"\"\"Retrieves players with a high injury risk.\"\"\"\n",
    "    print(\"Fetching players with high injury risk...\")\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Player)-[:SUFFERED]->(i:Injury)\n",
    "    WHERE i.risk >= 0.8\n",
    "    RETURN p.name AS player, i.total_days AS total_days_injured, i.risk AS injury_risk\n",
    "    ORDER BY i.risk DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    return query_to_dataframe(driver, query)\n",
    "\n",
    "def get_team_strategies(driver):\n",
    "    \"\"\"Retrieves team strategies and associated needs.\"\"\"\n",
    "    print(\"Fetching team strategies and needs...\")\n",
    "    query = \"\"\"\n",
    "    MATCH (t:Team)\n",
    "    RETURN t.name AS team, t.strategy AS strategy, t.needs AS needs\n",
    "    \"\"\"\n",
    "    return query_to_dataframe(driver, query)\n",
    "\n",
    "def get_top_players_by_vorp(driver, season):\n",
    "    \"\"\"Retrieves top players by VORP for a given season.\"\"\"\n",
    "    print(f\"Fetching top players by VORP for season: {season}\")\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Player)-[:POSSESSES]->(stat:Statistics {season: $season})\n",
    "    RETURN p.name AS player, stat.vorp_total AS vorp\n",
    "    ORDER BY stat.vorp_total DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    parameters = {\"season\": season}\n",
    "    return query_to_dataframe(driver, query, parameters)\n",
    "\n",
    "def main(season='2023-24'):\n",
    "    \"\"\"Main function to connect to Neo4j, retrieve data, and print the results.\"\"\"\n",
    "    print(\"Starting Neo4j test function execution...\")\n",
    "    \n",
    "    try:\n",
    "        driver = connect_to_neo4j()\n",
    "        \n",
    "        print(\"Retrieving player statistics...\")\n",
    "        player_stats_df = get_player_statistics(driver, season)\n",
    "        print(\"Player Statistics:\\n\", player_stats_df)\n",
    "        \n",
    "        print(\"\\nRetrieving player contracts...\")\n",
    "        player_contracts_df = get_player_contracts(driver, season)\n",
    "        print(\"Player Contracts:\\n\", player_contracts_df)\n",
    "        \n",
    "        print(\"\\nRetrieving top teams by salary...\")\n",
    "        team_salary_df = get_top_teams_by_salary(driver, season)\n",
    "        print(\"Top Teams by Salary:\\n\", team_salary_df)\n",
    "        \n",
    "        print(\"\\nRetrieving players with high injury risk...\")\n",
    "        injury_risk_df = get_players_with_high_injury_risk(driver)\n",
    "        print(\"Players with High Injury Risk:\\n\", injury_risk_df)\n",
    "        \n",
    "        print(\"\\nRetrieving team strategies and needs...\")\n",
    "        team_strategy_df = get_team_strategies(driver)\n",
    "        print(\"Team Strategies:\\n\", team_strategy_df)\n",
    "        \n",
    "        print(\"\\nRetrieving top players by VORP...\")\n",
    "        top_vorp_df = get_top_players_by_vorp(driver, season)\n",
    "        print(\"Top Players by VORP:\\n\", top_vorp_df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Neo4j data testing: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/model_loading.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/model_loading.py\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "def load_llm(model_name):\n",
    "    \"\"\"Loads the LLM model.\"\"\"\n",
    "    llm = ChatOllama(model=model_name, temperature=0)\n",
    "    print(f\"LLM model '{model_name}' loaded successfully.\")\n",
    "    return llm\n",
    "\n",
    "def test_llm(llm, prompt):\n",
    "    \"\"\"Runs a test prompt and shows the output.\"\"\"\n",
    "    response = llm([HumanMessage(content=prompt)])\n",
    "    print(f\"Test Prompt: {prompt}\\nLLM Response: {response.content}\")\n",
    "    return response.content\n",
    "\n",
    "def main(model_name='tomasonjo/llama3-text2cypher-demo', debug=False):\n",
    "    try:\n",
    "        if debug:\n",
    "            print(\"Debug mode enabled.\")\n",
    "        \n",
    "        # Step 1: Load LLM\n",
    "        llm = load_llm(model_name)\n",
    "        \n",
    "        # Step 2: Test LLM with a sample prompt\n",
    "        test_prompt = \"Why is the sky blue?\"\n",
    "        response = test_llm(llm, test_prompt)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"LLM Response Retrieved.\")\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during LLM model loading: {e}\")\n",
    "\n",
    "# Example usage without argparse\n",
    "if __name__ == '__main__':\n",
    "    # You can call main with debug=True to see additional print statements for debugging\n",
    "    main(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/graphqa_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/graphqa_functions.py\n",
    "from utility_functions import load_env_variables, connect_to_neo4j\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.tools import Tool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# Step 2: Setup the GraphCypherQAChain\n",
    "def setup_graphqa_chain(llm, graph, cypher_prompt):\n",
    "    \"\"\"Sets up the GraphCypherQAChain with schema, cypher_prompt, and configurations.\"\"\"\n",
    "    \n",
    "    return GraphCypherQAChain.from_llm(\n",
    "        cypher_llm=llm,\n",
    "        qa_llm=llm,\n",
    "        validate_cypher=True,\n",
    "        graph=graph,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        return_direct=True,\n",
    "        cypher_prompt=cypher_prompt,\n",
    "        allow_dangerous_requests=True,\n",
    "    )\n",
    "\n",
    "# Step 3: Validate the generated Cypher query against the schema\n",
    "def validate_generated_query(query, driver, schema):\n",
    "    \"\"\"Validates the generated Cypher query against the actual schema to identify potential issues.\"\"\"\n",
    "    schema_properties = [re.sub(r'\\.\\n-.*$', '', prop.strip().lower()) for prop in schema.split(\"Properties: \")[1].split(\",\")]\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"CALL db.schema.nodeTypeProperties()\")\n",
    "        db_properties = {record[\"propertyName\"].lower() for record in result}\n",
    "    \n",
    "    missing_properties = [prop for prop in schema_properties if prop not in db_properties]\n",
    "    print(f\"Missing Properties: {missing_properties}\")\n",
    "    \n",
    "    return missing_properties\n",
    "\n",
    "# Step 4: Handle missing properties in the generated query\n",
    "def handle_missing_properties(missing_properties, query):\n",
    "    \"\"\"Removes references to missing properties from the Cypher query.\"\"\"\n",
    "    if not missing_properties:\n",
    "        return query\n",
    "    \n",
    "    for prop in missing_properties:\n",
    "        query = re.sub(fr\"stat\\.{prop}\\s*\", '', query)\n",
    "    \n",
    "    print(f\"Adjusted Query After Removing Missing Properties:\\n{query}\")\n",
    "    return query\n",
    "\n",
    "# Step 5: Add per-game calculations to the query if necessary\n",
    "def add_per_game_calculations(query):\n",
    "    \"\"\"Adjusts the query for per-game calculations by dividing cumulative stats by games played.\"\"\"\n",
    "    print(f\"Original Query Before Per-Game Calculations:\\n{query}\")\n",
    "    \n",
    "    total_stat_mappings = {\n",
    "        \"ppg\": \"stat.ppg / stat.games_played\",\n",
    "        \"assists_total\": \"stat.assists_total / stat.games_played\",\n",
    "        \"rebounds_total\": \"stat.rebounds_total / stat.games_played\",\n",
    "        \"steals_total\": \"stat.steals_total / stat.games_played\",\n",
    "        \"blocks_total\": \"stat.blocks_total / stat.games_played\",\n",
    "        \"turnovers_total\": \"stat.turnovers_total / stat.games_played\",\n",
    "        \"personal_fouls_total\": \"stat.personal_fouls_total / stat.games_played\",\n",
    "        \"win_shares_total\": \"stat.win_shares_total / stat.games_played\",\n",
    "        \"offensive_win_shares_total\": \"stat.offensive_win_shares_total / stat.games_played\",\n",
    "        \"defensive_win_shares_total\": \"stat.defensive_win_shares_total / stat.games_played\",\n",
    "        \"vorp_total\": \"stat.vorp_total / stat.games_played\",\n",
    "    }\n",
    "    \n",
    "    for total_stat, per_game_stat in total_stat_mappings.items():\n",
    "        query = re.sub(fr\"stat\\.{total_stat}\", per_game_stat, query, flags=re.IGNORECASE)\n",
    "    \n",
    "    print(f\"Adjusted Query After Per-Game Calculations:\\n{query}\")\n",
    "    return query\n",
    "\n",
    "# Step 6: Run the Cypher query\n",
    "def run_cypher_query(query, driver):\n",
    "    \"\"\"Executes the Cypher query on the Neo4j database and returns the results.\"\"\"\n",
    "    print(f\"Executing Query:\\n{query}\")\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "\n",
    "# Step 7: Agent REPL loop for error handling and query debugging\n",
    "def agent_repl_loop(sample_question, schema, driver, llm, repl_tool, cypher_prompt):\n",
    "    \"\"\"Runs the REPL loop to handle query generation and errors, and returns intermediate steps for debugging.\"\"\"\n",
    "    # Initialize variables to return intermediate steps\n",
    "    prompt_text = cypher_prompt.format(schema=schema, question=sample_question)\n",
    "    llm_response_content = \"\"\n",
    "    adjusted_query = \"\"\n",
    "    query_result = []\n",
    "\n",
    "    try:\n",
    "        # Step 1: Generate the initial Cypher query using the language model\n",
    "        llm_response = llm([HumanMessage(content=prompt_text)])\n",
    "        llm_response_content = llm_response.content.strip()\n",
    "        \n",
    "        # Display generated query\n",
    "        print(f\"Generated Query:\\n{llm_response_content}\")\n",
    "\n",
    "        # Step 2: Add per-game calculations if needed\n",
    "        adjusted_query = add_per_game_calculations(llm_response_content)\n",
    "        \n",
    "        # Step 3: Execute the adjusted Cypher query on Neo4j\n",
    "        query_result = run_cypher_query(adjusted_query, driver)\n",
    "        \n",
    "        # Display query results\n",
    "        print(\"Query Results:\")\n",
    "        for record in query_result:\n",
    "            print(record)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capture error information and use the REPL tool to debug\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        repl_output = repl_tool.func(f\"print('{str(e)}')\")\n",
    "        print(f\"Python REPL Output for Debugging:\\n{repl_output}\")\n",
    "    \n",
    "    # Return all relevant data for display in the Streamlit app\n",
    "    return {\n",
    "        \"prompt_text\": prompt_text,\n",
    "        \"generated_query\": llm_response_content,\n",
    "        \"adjusted_query\": adjusted_query,\n",
    "        \"query_result\": query_result,\n",
    "    }\n",
    "\n",
    "\n",
    "# Step 8: Main function to initialize and run the agent with a test question\n",
    "def main(question='Who are the top 5 players in the 2023-24 season based on assist total?'):\n",
    "    try:\n",
    "        driver = connect_to_neo4j()\n",
    "        graph = Neo4jGraph(url=os.getenv(\"NEO4J_URI\"), username=os.getenv(\"NEO4J_USERNAME\"), password=os.getenv(\"NEO4J_PASSWORD\"))\n",
    "        llm = ChatOllama(model='tomasonjo/llama3-text2cypher-demo', temperature=0)\n",
    "        python_repl = PythonREPL()\n",
    "        repl_tool = Tool(\n",
    "            name=\"python_repl\",\n",
    "            description=\"A Python shell for executing commands.\",\n",
    "            func=python_repl.run,\n",
    "        )\n",
    "        \n",
    "        # Define schema and cypher_prompt\n",
    "        schema = \"\"\"\n",
    "        Nodes:\n",
    "        - Player: Represents an NBA player. Properties: name, age, position, years_of_service, injury_risk, season_salary, season, per, ws, bpm, vorp.\n",
    "        - Team: Represents an NBA team. Properties: name, team_id, needs, strategy, cap_space.\n",
    "        - Season: Represents a specific NBA season. Properties: name.\n",
    "        - Contract: Represents player contracts. Properties: player_name, salary, cap, luxury_tax, duration, player_option, team_option, no_trade_clause.\n",
    "        - Statistics: Represents player statistics. Properties: player, season, ppg, assists_total, rebounds_total, steals_total, blocks_total, turnovers_total, personal_fouls_total, win_shares_total, offensive_win_shares_total, defensive_win_shares_total, vorp_total, games_played.\n",
    "        - Injury: Represents player injury details. Properties: player, total_days, injury_periods, risk, injury_history.\n",
    "        \"\"\"\n",
    "        \n",
    "        cypher_prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "            You are a Cypher query expert for a Neo4j database with the following schema:\n",
    "            \n",
    "            Schema:\n",
    "            Nodes:\n",
    "            - Player: Represents an NBA player with properties like name, assists_total, and other statistics.\n",
    "            - Team: Represents an NBA team with a property 'season' (e.g., '2023-24').\n",
    "            \n",
    "            Relationships:\n",
    "            - :PARTICIPATED_IN (Player)-[:PARTICIPATED_IN]->(Team): Links players to the teams for a given season.\n",
    "\n",
    "            Use the schema above to generate a Cypher query that answers the given question.\n",
    "            Make the query flexible by using case-insensitive matching and partial string matching where appropriate.\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Cypher Query:\n",
    "            \"\"\",\n",
    "            input_variables=[\"schema\", \"question\"]\n",
    "        )\n",
    "\n",
    "        \n",
    "        agent_repl_loop(question, schema, driver, llm, repl_tool, cypher_prompt)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during GraphQA operations: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/graphqa_module.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/graphqa_module.py\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.tools import Tool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# --- SECTION 1: ENVIRONMENT SETUP AND CONNECTIONS ---\n",
    "\n",
    "def load_environment():\n",
    "    \"\"\"Loads environment variables from the .env file.\"\"\"\n",
    "    dotenv_path = os.path.join(os.getcwd(), '../../.env')\n",
    "    load_dotenv(dotenv_path)\n",
    "\n",
    "def create_neo4j_driver():\n",
    "    \"\"\"Initializes the Neo4j driver using credentials from environment variables.\"\"\"\n",
    "    uri = os.getenv(\"NEO4J_URI\")\n",
    "    username = os.getenv(\"NEO4J_USERNAME\")\n",
    "    password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "    return GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def initialize_graph_connection():\n",
    "    \"\"\"Initializes the Neo4jGraph connection for LangChain's graph QA chain.\"\"\"\n",
    "    uri = os.getenv(\"NEO4J_URI\")\n",
    "    username = os.getenv(\"NEO4J_USERNAME\")\n",
    "    password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "    return Neo4jGraph(url=uri, username=username, password=password)\n",
    "\n",
    "\n",
    "# --- SECTION 2: PROMPT AND LLM INITIALIZATION ---\n",
    "\n",
    "def initialize_llm():\n",
    "    \"\"\"Initializes the ChatOllama model for Cypher query generation.\"\"\"\n",
    "    cypher_model = 'tomasonjo/llama3-text2cypher-demo'\n",
    "    return ChatOllama(model=cypher_model, temperature=0)\n",
    "\n",
    "def create_cypher_prompt_template():\n",
    "    \"\"\"Creates a PromptTemplate for generating Cypher queries based on schema.\"\"\"\n",
    "    \n",
    "    schema = \"\"\"\n",
    "    Nodes:\n",
    "    - Player: Represents an NBA player. Properties: name, age, position, years_of_service, injury_risk, season_salary, season, per, ws, bpm, vorp.\n",
    "    - Team: Represents an NBA team. Properties: name, team_id, needs, strategy, cap_space.\n",
    "    - Season: Represents a specific NBA season. Properties: name.\n",
    "    - Contract: Represents player contracts. Properties: player_name, salary, cap, luxury_tax, duration, player_option, team_option, no_trade_clause.\n",
    "    - Statistics: Represents player statistics. Properties: player, season, ppg, assists_total, rebounds_total, steals_total, blocks_total, turnovers_total, personal_fouls_total, win_shares_total, offensive_win_shares_total, defensive_win_shares_total, vorp_total, games_played.\n",
    "    - Injury: Represents player injury details. Properties: player, total_days, injury_periods, risk, injury_history.\n",
    "\n",
    "    Relationships:\n",
    "    - Player -[:HAS_PLAYED_FOR]-> Team\n",
    "    - Player -[:PARTICIPATED_IN]-> Season\n",
    "    - Player -[:HAS_CONTRACT]-> Contract\n",
    "    - Player -[:POSSESSES]-> Statistics\n",
    "    - Player -[:SUFFERED]-> Injury\n",
    "    - Team -[:HAS_PLAYER]-> Player\n",
    "    - Team -[:CURRENT_TEAM]-> Player\n",
    "    \"\"\"\n",
    "\n",
    "    return PromptTemplate(\n",
    "        template=f\"\"\"\n",
    "        You are a Cypher query expert for a Neo4j database with the following schema:\n",
    "        \n",
    "        Schema:\n",
    "        {schema}\n",
    "        \n",
    "        Use the schema above to generate a Cypher query that answers the given question.\n",
    "        Make the query flexible by using case-insensitive matching and partial string matching where appropriate.\n",
    "        Focus on searching player statistics, contracts, and team details.\n",
    "\n",
    "        Now, generate a Cypher query for the following question:\n",
    "\n",
    "        Question: {{question}}\n",
    "        \n",
    "        Cypher Query:\n",
    "        \"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# --- SECTION 3: QUERY GENERATION AND MODIFICATION ---\n",
    "\n",
    "def generate_query(llm, prompt_template, schema, question):\n",
    "    \"\"\"Generates a Cypher query from an LLM using a schema and question.\"\"\"\n",
    "    prompt_text = prompt_template.format(schema=schema, question=question)\n",
    "    print(f\"Generated Prompt:\\n{prompt_text}\")\n",
    "    llm_response = llm([HumanMessage(content=prompt_text)])\n",
    "    return llm_response.content.strip()\n",
    "\n",
    "def add_per_game_calculations(query):\n",
    "    \"\"\"Adjusts the query for per-game calculations by dividing cumulative stats by games played.\"\"\"\n",
    "    print(f\"Original Query Before Per-Game Calculations:\\n{query}\")\n",
    "    \n",
    "    total_stat_mappings = {\n",
    "        \"ppg\": \"stat.ppg / stat.games_played\",\n",
    "        \"assists_total\": \"stat.assists_total / stat.games_played\",\n",
    "        \"rebounds_total\": \"stat.rebounds_total / stat.games_played\",\n",
    "        # Other stat mappings can go here\n",
    "    }\n",
    "    \n",
    "    for total_stat, per_game_stat in total_stat_mappings.items():\n",
    "        query = re.sub(fr\"stat\\.{total_stat}\", per_game_stat, query, flags=re.IGNORECASE)\n",
    "    \n",
    "    print(f\"Adjusted Query After Per-Game Calculations:\\n{query}\")\n",
    "    return query\n",
    "\n",
    "def handle_missing_properties(missing_properties, query):\n",
    "    \"\"\"Removes references to missing properties from the Cypher query.\"\"\"\n",
    "    if not missing_properties:\n",
    "        return query\n",
    "    \n",
    "    for prop in missing_properties:\n",
    "        query = re.sub(fr\"stat\\.{prop}\\s*\", '', query)\n",
    "    print(f\"Adjusted Query After Removing Missing Properties:\\n{query}\")\n",
    "    return query\n",
    "\n",
    "\n",
    "# --- SECTION 4: VALIDATION AND EXECUTION ---\n",
    "\n",
    "def validate_generated_query(query, driver, schema):\n",
    "    \"\"\"Validates the generated Cypher query against the actual schema to identify potential issues.\"\"\"\n",
    "    schema_properties = [\n",
    "        re.sub(r'\\.\\n-.*$', '', prop.strip().lower())\n",
    "        for prop in schema.split(\"Properties: \")[1].split(\",\")\n",
    "    ]\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"CALL db.schema.nodeTypeProperties()\")\n",
    "        db_properties = {record[\"propertyName\"].lower() for record in result}\n",
    "    \n",
    "    missing_properties = [prop for prop in schema_properties if prop not in db_properties]\n",
    "    print(f\"Missing Properties: {missing_properties}\")\n",
    "    \n",
    "    return missing_properties\n",
    "\n",
    "def run_cypher_query(query, driver):\n",
    "    \"\"\"Executes the given Cypher query on the Neo4j database and returns the results.\"\"\"\n",
    "    print(f\"Executing Query:\\n{query}\")\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "\n",
    "# --- SECTION 5: MAIN LOOP AND EXECUTION ---\n",
    "\n",
    "def agent_repl_loop(question, driver, llm, schema, prompt_template, repl_tool):\n",
    "    \"\"\"Runs the REPL loop to handle query generation and debugging autonomously.\"\"\"\n",
    "    results = {\n",
    "        \"prompt_text\": None,\n",
    "        \"generated_query\": None,\n",
    "        \"adjusted_query\": None,\n",
    "        \"query_result\": None,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Generate initial query\n",
    "        results[\"prompt_text\"] = prompt_template.format(schema=schema, question=question)\n",
    "        raw_query = generate_query(llm, prompt_template, schema, question)\n",
    "        print(f\"Generated Raw Query:\\n{raw_query}\")\n",
    "        \n",
    "        results[\"generated_query\"] = raw_query\n",
    "\n",
    "        # Validate and adjust query\n",
    "        missing_properties = validate_generated_query(raw_query, driver, schema)\n",
    "        adjusted_query = handle_missing_properties(missing_properties, raw_query)\n",
    "        final_query = add_per_game_calculations(adjusted_query)\n",
    "        \n",
    "        results[\"adjusted_query\"] = final_query\n",
    "\n",
    "        # Execute query\n",
    "        query_results = run_cypher_query(final_query, driver)\n",
    "        print(\"Query Results:\")\n",
    "        for record in query_results:\n",
    "            print(record)\n",
    "        \n",
    "        results[\"query_result\"] = query_results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        if repl_tool:\n",
    "            repl_tool.func(f\"print('{str(e)}')\")\n",
    "    \n",
    "    return results  # Return the results dictionary\n",
    "\n",
    "\n",
    "# Define the schema for the graph, fixing VORP issue and capitalized properties\n",
    "schema = \"\"\"\n",
    "Nodes:\n",
    "- Player: Represents an NBA player. Properties: name, age, position, years_of_service, injury_risk, season_salary, season, per, ws, bpm, vorp.\n",
    "- Team: Represents an NBA team. Properties: name, team_id, needs, strategy, cap_space.\n",
    "- Season: Represents a specific NBA season. Properties: name.\n",
    "- Contract: Represents player contracts. Properties: player_name, salary, cap, luxury_tax, duration, player_option, team_option, no_trade_clause.\n",
    "- Statistics: Represents player statistics. Properties: player, season, ppg, assists_total, rebounds_total, steals_total, blocks_total, turnovers_total, personal_fouls_total, win_shares_total, offensive_win_shares_total, defensive_win_shares_total, vorp_total, games_played.\n",
    "- Injury: Represents player injury details. Properties: player, total_days, injury_periods, risk, injury_history.\n",
    "\n",
    "Relationships:\n",
    "- Player -[:HAS_PLAYED_FOR]-> Team\n",
    "- Player -[:PARTICIPATED_IN]-> Season\n",
    "- Player -[:HAS_CONTRACT]-> Contract\n",
    "- Player -[:POSSESSES]-> Statistics\n",
    "- Player -[:SUFFERED]-> Injury\n",
    "- Team -[:HAS_PLAYER]-> Player\n",
    "- Team -[:CURRENT_TEAM]-> Player\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to set up connections, load schema, and run REPL loop.\"\"\"\n",
    "    load_environment()\n",
    "    driver = create_neo4j_driver()\n",
    "    llm = initialize_llm()\n",
    "    graph = initialize_graph_connection()\n",
    "    repl_tool = Tool(name=\"python_repl\", description=\"Python shell for REPL.\", func=PythonREPL().run)\n",
    "    \n",
    "    # Sample question\n",
    "    sample_question = \"Who are the top 5 players in the 2023-24 season based on assist total?\"\n",
    "    \n",
    "    # Prompt setup\n",
    "    prompt_template = create_cypher_prompt_template()\n",
    "    agent_repl_loop(sample_question, driver, llm, schema, prompt_template, repl_tool)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/modules/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/modules/main.py\n",
    "\n",
    "from graphqa_module import (\n",
    "    load_environment,\n",
    "    create_neo4j_driver,\n",
    "    initialize_llm,\n",
    "    create_cypher_prompt_template,\n",
    "    validate_generated_query,\n",
    "    add_per_game_calculations,\n",
    "    handle_missing_properties,\n",
    "    agent_repl_loop,\n",
    ")\n",
    "from utility_functions import connect_to_neo4j\n",
    "from data_cleaning import (\n",
    "    load_data, \n",
    "    data_initial_summary, \n",
    "    clean_data, \n",
    "    check_for_duplicates, \n",
    "    map_team_ids, \n",
    "    add_suffixes_to_columns, \n",
    "    final_data_check\n",
    ")\n",
    "from neo4j_data_preprocess_ingest import (\n",
    "    clear_database,\n",
    "    clear_constraints_and_indexes,\n",
    "    setup_schema_with_cleanup,\n",
    "    setup_indexes,\n",
    "    insert_enhanced_data,\n",
    "    calculate_and_set_trade_value\n",
    ")\n",
    "from neo4j_test_functions import get_player_statistics, get_player_contracts\n",
    "from model_loading import load_llm, test_llm\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def check_neo4j_connection():\n",
    "    \"\"\"Tests Neo4j connection using utility functions.\"\"\"\n",
    "    print(\"Testing Neo4j connection...\")\n",
    "    try:\n",
    "        driver = connect_to_neo4j()\n",
    "        driver.close()\n",
    "        print(\"Neo4j connection successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Neo4j connection test failed: {e}\")\n",
    "\n",
    "\n",
    "def run_data_cleaning():\n",
    "    \"\"\"Executes data cleaning pipeline.\"\"\"\n",
    "    load_dotenv('/workspaces/custom_ollama_docker/.env')\n",
    "    data_file = os.getenv('DATA_FILE', '/workspaces/custom_ollama_docker/data/neo4j/raw/nba_player_data_final_inflated.csv')\n",
    "    output_file = os.getenv('CLEANED_DATA_FILE', '/workspaces/custom_ollama_docker/data/neo4j/processed/nba_player_data_cleaned.csv')\n",
    "    \n",
    "    try:\n",
    "        dataframe = load_data(data_file)\n",
    "        print(f\"Loaded data with shape: {dataframe.shape}\")\n",
    "        \n",
    "        data_initial_summary(dataframe, debug=True)\n",
    "        \n",
    "        # Data cleaning and validation pipeline\n",
    "        dataframe_cleaned = clean_data(dataframe, debug=True)\n",
    "        check_for_duplicates(dataframe_cleaned, debug=True)\n",
    "        dataframe_mapped = map_team_ids(dataframe_cleaned, debug=True)\n",
    "        dataframe_final = add_suffixes_to_columns(dataframe_mapped, debug=True)\n",
    "        final_data_check(dataframe_final, debug=True)\n",
    "        \n",
    "        dataframe_final.to_csv(output_file, index=False)\n",
    "        print(f\"Preprocessed data saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Data cleaning process failed: {e}\")\n",
    "\n",
    "\n",
    "def run_data_ingestion():\n",
    "    \"\"\"Executes data ingestion into Neo4j.\"\"\"\n",
    "    load_dotenv('/workspaces/custom_ollama_docker/.env')\n",
    "    data_file = '/workspaces/custom_ollama_docker/data/neo4j/processed/nba_player_data_cleaned.csv'\n",
    "\n",
    "    try:\n",
    "        driver = connect_to_neo4j()\n",
    "        dataframe = pd.read_csv(data_file)\n",
    "        data_dicts = dataframe.to_dict(orient='records')\n",
    "        print(f\"Loaded {len(data_dicts)} records from {data_file}.\")\n",
    "\n",
    "        with driver.session() as session:\n",
    "            clear_database(session)\n",
    "            clear_constraints_and_indexes(session)\n",
    "            setup_schema_with_cleanup(session)\n",
    "            setup_indexes(session)\n",
    "            print(\"Database schema and indexes set up successfully.\")\n",
    "\n",
    "            for player_data in data_dicts:\n",
    "                session.execute_write(insert_enhanced_data, player_data)\n",
    "                session.execute_write(calculate_and_set_trade_value, player_data[\"Player\"])\n",
    "\n",
    "            print(\"Data inserted into Neo4j successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Data ingestion process failed: {e}\")\n",
    "\n",
    "\n",
    "def run_neo4j_test_queries(season='2023-24'):\n",
    "    \"\"\"Tests Neo4j data retrieval functions.\"\"\"\n",
    "    print(f\"Running Neo4j test queries for season {season}...\")\n",
    "    try:\n",
    "        driver = connect_to_neo4j()\n",
    "        \n",
    "        print(\"Retrieving player statistics...\")\n",
    "        player_stats_df = get_player_statistics(driver, season)\n",
    "        print(\"Player Statistics:\\n\", player_stats_df.head())\n",
    "        \n",
    "        print(\"\\nRetrieving player contracts...\")\n",
    "        player_contracts_df = get_player_contracts(driver, season)\n",
    "        print(\"Player Contracts:\\n\", player_contracts_df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Neo4j test queries failed: {e}\")\n",
    "\n",
    "\n",
    "def run_model_loading(model_name='tomasonjo/llama3-text2cypher-demo'):\n",
    "    \"\"\"Loads and tests the specified LLM model.\"\"\"\n",
    "    try:\n",
    "        llm = load_llm(model_name)\n",
    "        test_prompt = \"Why is the sky blue?\"\n",
    "        response = test_llm(llm, test_prompt)\n",
    "        print(f\"Model test response: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Model loading process failed: {e}\")\n",
    "\n",
    "\n",
    "def run_graphqa(question='Who are the top 5 players in the 2023-24 season based on assist total?'):\n",
    "    \"\"\"Runs the GraphQA agent for the specified question.\"\"\"\n",
    "    load_environment()\n",
    "    driver = create_neo4j_driver()\n",
    "    llm = initialize_llm()\n",
    "    prompt_template = create_cypher_prompt_template()\n",
    "    \n",
    "    try:\n",
    "        agent_repl_loop(\n",
    "            question=question,\n",
    "            driver=driver,\n",
    "            llm=llm,\n",
    "            schema=schema,\n",
    "            prompt_template=prompt_template,\n",
    "            repl_tool=Tool(name=\"python_repl\", description=\"Python shell for REPL.\", func=PythonREPL().run)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"GraphQA agent execution failed: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the pipeline sequentially.\"\"\"\n",
    "    check_neo4j_connection()\n",
    "    \n",
    "    # # Data cleaning\n",
    "    # run_data_cleaning()\n",
    "    \n",
    "    # # Data ingestion into Neo4j\n",
    "    # run_data_ingestion()\n",
    "    \n",
    "    # Neo4j test queries\n",
    "    run_neo4j_test_queries(season='2023-24')\n",
    "    \n",
    "    # Model loading and testing\n",
    "    run_model_loading(model_name='tomasonjo/llama3-text2cypher-demo')\n",
    "    \n",
    "    # GraphQA setup and query test\n",
    "    run_graphqa(question='Who are the top 5 players in the 2023-24 season based on assist total?')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../src/neo4j_model/streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../src/neo4j_model/streamlit_app.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'modules')))\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from modules.graphqa_module import (\n",
    "    load_environment,\n",
    "    create_neo4j_driver,\n",
    "    initialize_llm,\n",
    "    create_cypher_prompt_template,\n",
    "    agent_repl_loop,\n",
    ")\n",
    "from modules.utility_functions import connect_to_neo4j\n",
    "from modules.data_cleaning import (\n",
    "    load_data,\n",
    "    data_initial_summary,\n",
    "    clean_data,\n",
    "    check_for_duplicates,\n",
    "    map_team_ids,\n",
    "    add_suffixes_to_columns,\n",
    "    final_data_check\n",
    ")\n",
    "from modules.neo4j_data_preprocess_ingest import (\n",
    "    clear_database,\n",
    "    clear_constraints_and_indexes,\n",
    "    setup_schema_with_cleanup,\n",
    "    setup_indexes,\n",
    "    insert_enhanced_data,\n",
    "    calculate_and_set_trade_value\n",
    ")\n",
    "from modules.neo4j_test_functions import (\n",
    "    get_player_statistics,\n",
    "    get_player_contracts,\n",
    "    get_top_teams_by_salary,\n",
    "    get_players_with_high_injury_risk,\n",
    "    get_team_strategies,\n",
    "    get_top_players_by_vorp\n",
    ")\n",
    "\n",
    "\n",
    "schema = \"\"\"\n",
    "Nodes:\n",
    "- Player: Represents an NBA player. Properties: name, age, position, years_of_service, injury_risk, season_salary, season, per, ws, bpm, vorp.\n",
    "- Team: Represents an NBA team. Properties: name, team_id, needs, strategy, cap_space.\n",
    "- Season: Represents a specific NBA season. Properties: name.\n",
    "- Contract: Represents player contracts. Properties: player_name, salary, cap, luxury_tax, duration, player_option, team_option, no_trade_clause.\n",
    "- Statistics: Represents player statistics. Properties: player, season, ppg, assists_total, rebounds_total, steals_total, blocks_total, turnovers_total, personal_fouls_total, win_shares_total, offensive_win_shares_total, defensive_win_shares_total, vorp_total, games_played.\n",
    "- Injury: Represents player injury details. Properties: player, total_days, injury_periods, risk, injury_history.\n",
    "\n",
    "Relationships:\n",
    "- Player -[:HAS_PLAYED_FOR]-> Team\n",
    "- Player -[:PARTICIPATED_IN]-> Season\n",
    "- Player -[:HAS_CONTRACT]-> Contract\n",
    "- Player -[:POSSESSES]-> Statistics\n",
    "- Player -[:SUFFERED]-> Injury\n",
    "- Team -[:HAS_PLAYER]-> Player\n",
    "- Team -[:CURRENT_TEAM]-> Player\n",
    "\"\"\"\n",
    "\n",
    "# App setup\n",
    "st.title(\"NBA Player Data Analysis with Neo4j and Llama3\")\n",
    "st.sidebar.title(\"Workflow Steps\")\n",
    "\n",
    "# --- Step 1: Load and Clean Data ---\n",
    "if st.sidebar.checkbox(\"Step 1: Load and Clean Data\"):\n",
    "    st.subheader(\"Data Loading and Cleaning\")\n",
    "    load_dotenv('/workspaces/custom_ollama_docker/.env')\n",
    "    data_file = st.text_input(\"Enter path to raw data file:\", \"/workspaces/custom_ollama_docker/data/neo4j/raw/nba_player_data_final_inflated.csv\")\n",
    "    output_file = \"/workspaces/custom_ollama_docker/data/neo4j/processed/nba_player_data_cleaned.csv\"\n",
    "    \n",
    "    if st.button(\"Load and Clean Data\"):\n",
    "        try:\n",
    "            dataframe = load_data(data_file)\n",
    "            st.write(\"Initial Data Loaded:\", dataframe.head())\n",
    "            \n",
    "            # Data cleaning steps\n",
    "            data_initial_summary(dataframe, debug=True)\n",
    "            dataframe_cleaned = clean_data(dataframe, debug=True)\n",
    "            check_for_duplicates(dataframe_cleaned, debug=True)\n",
    "            dataframe_mapped = map_team_ids(dataframe_cleaned, debug=True)\n",
    "            dataframe_final = add_suffixes_to_columns(dataframe_mapped, debug=True)\n",
    "            final_data_check(dataframe_final, debug=True)\n",
    "            \n",
    "            dataframe_final.to_csv(output_file, index=False)\n",
    "            st.success(f\"Preprocessed data saved to {output_file}\")\n",
    "            st.write(\"Cleaned Data:\", dataframe_final.head())\n",
    "        except Exception as e:\n",
    "            st.error(f\"Data cleaning process failed: {e}\")\n",
    "\n",
    "# --- Step 2: Ingest Data into Neo4j ---\n",
    "if st.sidebar.checkbox(\"Step 2: Ingest Data into Neo4j\"):\n",
    "    st.subheader(\"Data Ingestion into Neo4j\")\n",
    "    load_dotenv('/workspaces/custom_ollama_docker/.env')\n",
    "    data_file = \"/workspaces/custom_ollama_docker/data/neo4j/processed/nba_player_data_cleaned.csv\"\n",
    "    \n",
    "    if st.button(\"Ingest Data\"):\n",
    "        try:\n",
    "            driver = connect_to_neo4j()\n",
    "            dataframe = pd.read_csv(data_file)\n",
    "            data_dicts = dataframe.to_dict(orient='records')\n",
    "            st.write(f\"Loaded {len(data_dicts)} records for ingestion.\")\n",
    "            \n",
    "            with driver.session() as session:\n",
    "                clear_database(session)\n",
    "                clear_constraints_and_indexes(session)\n",
    "                setup_schema_with_cleanup(session)\n",
    "                setup_indexes(session)\n",
    "                st.write(\"Database schema and indexes set up successfully.\")\n",
    "                \n",
    "                for player_data in data_dicts:\n",
    "                    session.execute_write(insert_enhanced_data, player_data)\n",
    "                    session.execute_write(calculate_and_set_trade_value, player_data[\"Player\"])\n",
    "\n",
    "                st.success(\"Data inserted into Neo4j successfully.\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Data ingestion process failed: {e}\")\n",
    "\n",
    "# --- Step 3: Test Neo4j Queries ---\n",
    "if st.sidebar.checkbox(\"Step 3: Test Neo4j Queries\"):\n",
    "    st.subheader(\"Test Data Retrieval from Neo4j\")\n",
    "    season = st.text_input(\"Enter season (e.g., '2023-24'):\", \"2023-24\")\n",
    "    query_type = st.selectbox(\"Select a query to run:\", [\n",
    "        \"Player Statistics\",\n",
    "        \"Top Teams by Salary\",\n",
    "        \"Top Players by VORP\"\n",
    "    ])\n",
    "\n",
    "    if st.button(\"Run Test Query\"):\n",
    "        try:\n",
    "            driver = connect_to_neo4j()\n",
    "            \n",
    "            if query_type == \"Player Statistics\":\n",
    "                st.write(\"Retrieving player statistics...\")\n",
    "                query = \"\"\"\n",
    "                MATCH (p:Player)-[:POSSESSES]->(stat:Statistics {season: $season})\n",
    "                RETURN p.name AS player, stat.ppg AS points_per_game, stat.assists_total AS assists\n",
    "                \"\"\"\n",
    "                st.code(query, language=\"cypher\")\n",
    "                player_stats_df = get_player_statistics(driver, season)\n",
    "                st.write(\"Player Statistics:\", player_stats_df.head())\n",
    "            \n",
    "                \n",
    "            elif query_type == \"Top Teams by Salary\":\n",
    "                st.write(\"Retrieving top teams by salary...\")\n",
    "                query = \"\"\"\n",
    "                MATCH (t:Team)<-[:HAS_PLAYED_FOR]-(p:Player)-[:HAS_CONTRACT]->(c:Contract {season: $season})\n",
    "                RETURN t.name AS team, SUM(c.salary) AS total_salary\n",
    "                ORDER BY total_salary DESC\n",
    "                LIMIT 5\n",
    "                \"\"\"\n",
    "                st.code(query, language=\"cypher\")\n",
    "                team_salary_df = get_top_teams_by_salary(driver, season)\n",
    "                st.write(\"Top Teams by Salary:\", team_salary_df.head())\n",
    "                \n",
    "                \n",
    "            elif query_type == \"Top Players by VORP\":\n",
    "                st.write(\"Retrieving top players by VORP...\")\n",
    "                query = \"\"\"\n",
    "                MATCH (p:Player)-[:POSSESSES]->(stat:Statistics {season: $season})\n",
    "                RETURN p.name AS player, stat.vorp_total AS vorp\n",
    "                ORDER BY stat.vorp_total DESC\n",
    "                LIMIT 5\n",
    "                \"\"\"\n",
    "                st.code(query, language=\"cypher\")\n",
    "                top_vorp_df = get_top_players_by_vorp(driver, season)\n",
    "                st.write(\"Top Players by VORP:\", top_vorp_df.head())\n",
    "                \n",
    "        except Exception as e:\n",
    "            st.error(f\"Neo4j test queries failed: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 4: GraphQA with Llama3 ---\n",
    "if st.sidebar.checkbox(\"Step 4 : GraphQA with Llama3\"):\n",
    "    st.subheader(\"GraphQA - Ask Questions on NBA Data\")\n",
    "    load_environment()\n",
    "    driver = create_neo4j_driver()\n",
    "    llm = initialize_llm()\n",
    "    prompt_template = create_cypher_prompt_template()\n",
    "    \n",
    "    question = st.text_input(\"Enter your question about NBA data:\", \"Who are the top 5 players in the 2023-24 season based on assist total?\")\n",
    "    \n",
    "    if st.button(\"Run GraphQA\"):\n",
    "        try:\n",
    "            # Run the agent REPL loop and capture all intermediate outputs\n",
    "            results = agent_repl_loop(\n",
    "                question=question,  # Pass `question` instead of `sample_question`\n",
    "                schema=schema,\n",
    "                driver=driver,\n",
    "                llm=llm,\n",
    "                repl_tool=None,  # Optional: Python REPL for interactive debugging\n",
    "                prompt_template=prompt_template\n",
    "            )\n",
    "            \n",
    "            # Display the generated prompt\n",
    "            st.write(\"Generated Prompt:\")\n",
    "            st.code(results[\"prompt_text\"], language=\"plaintext\")\n",
    "\n",
    "            # Display the initial generated query\n",
    "            st.write(\"Generated Query:\")\n",
    "            st.code(results[\"generated_query\"], language=\"cypher\")\n",
    "\n",
    "            # Display the adjusted query if it was modified\n",
    "            if results[\"adjusted_query\"] != results[\"generated_query\"]:\n",
    "                st.write(\"Adjusted Query After Per-Game Calculations:\")\n",
    "                st.code(results[\"adjusted_query\"], language=\"cypher\")\n",
    "\n",
    "            # Show the query results\n",
    "            if results[\"query_result\"]:\n",
    "                st.write(\"Query Results:\")\n",
    "                st.write(pd.DataFrame(results[\"query_result\"]))  # Display results as a DataFrame\n",
    "            else:\n",
    "                st.write(\"No results returned from the query.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"GraphQA agent execution failed: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
